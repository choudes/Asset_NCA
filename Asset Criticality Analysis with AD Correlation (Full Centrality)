{"cells":[{"cell_type":"code","source":["!pip install pyvis -q\n","\n","import pandas as pd\n","import numpy as np\n","import networkx as nx\n","from pyvis.network import Network\n","import random\n","\n","def generate_and_save_data():\n","    \"\"\"Generates synthetic network flow, Zeek, and Active Directory data and saves them.\"\"\"\n","    print(\"Generating synthetic data...\")\n","    # --- Generate a common pool of IPs to ensure correlation ---\n","    internal_ips = [f'192.168.1.{i}' for i in range(1, 255)]\n","    server_ips = [f'10.0.0.{i}' for i in range(1, 255)]\n","    all_ips = internal_ips + server_ips\n","\n","    # --- 1. Generate synthetic netflow data ---\n","    num_netflow_entries = 1000\n","    netflow_data = {\n","        'source_ip': [random.choice(internal_ips) for _ in range(num_netflow_entries)],\n","        'dest_ip': [random.choice(server_ips) for _ in range(num_netflow_entries)],\n","        'dest_port': [random.choice([80, 443, 22, 3389, 53]) for _ in range(num_netflow_entries)],\n","        'protocol': [random.choice(['TCP', 'UDP']) for _ in range(num_netflow_entries)],\n","        'bytes': [random.randint(100, 10000) for _ in range(num_netflow_entries)],\n","    }\n","    netflow_df = pd.DataFrame(netflow_data)\n","    netflow_df.to_csv('netflow.csv', index=False)\n","    print(\"Synthetic netflow data saved to netflow.csv\")\n","\n","    # --- 2. Generate synthetic Zeek data ---\n","    num_zeek_entries = 500\n","    zeek_data = {\n","        'timestamp': [pd.to_datetime('2023-01-01') + pd.Timedelta(seconds=i*10) for i in range(num_zeek_entries)],\n","        'id.orig_h': [random.choice(internal_ips) for _ in range(num_zeek_entries)],\n","        'id.resp_h': [random.choice(server_ips) for _ in range(num_zeek_entries)],\n","        'service': [random.choice(['http', 'dns', 'ssh', 'rdp']) for _ in range(num_zeek_entries)],\n","    }\n","    zeek_df = pd.DataFrame(zeek_data)\n","    zeek_df.to_csv('zeek.csv', index=False)\n","    print(\"Synthetic Zeek data saved to zeek.csv\")\n","\n","    # --- 3. Generate synthetic Active Directory data ---\n","    num_ad_assets = len(all_ips)\n","    privileged_users = ['j.smith', 'a.jones', 'm.davis']\n","    domain_admins = ['administrator', 'domain.admin']\n","    standard_users = [f'user{i}' for i in range(200)]\n","\n","    dc_ip = random.choice(server_ips)\n","\n","    ad_data = []\n","    for ip in all_ips:\n","        is_dc = (ip == dc_ip)\n","        if is_dc:\n","            privilege = 'Domain Admin'\n","            user = random.choice(domain_admins)\n","            os = 'Windows Server 2022'\n","        elif '10.0.0.' in ip:\n","            privilege = random.choices(['Privileged User', 'Standard User'], weights=[0.4, 0.6], k=1)[0]\n","            user = random.choice(privileged_users) if privilege == 'Privileged User' else random.choice(standard_users)\n","            os = random.choice(['Windows Server 2019', 'Linux'])\n","        else:\n","            privilege = 'Standard User'\n","            user = random.choice(standard_users)\n","            os = 'Windows 11'\n","\n","        ad_data.append({\n","            'ip_address': ip,\n","            'hostname': f'HOST-{ip.replace(\".\", \"-\")}',\n","            'os': os,\n","            'is_domain_controller': is_dc,\n","            'last_logon_user': user,\n","            'user_privilege': privilege\n","        })\n","\n","    ad_df = pd.DataFrame(ad_data)\n","    ad_df.to_csv('ad_data.csv', index=False)\n","    print(\"Synthetic Active Directory data saved to ad_data.csv\")\n","    print(\"Data generation complete.\")\n","\n","\n","def load_data():\n","    \"\"\"Loads data from CSV files.\"\"\"\n","    print(\"Loading netflow.csv, zeek.csv, and ad_data.csv...\")\n","    try:\n","        netflow_df = pd.read_csv('netflow.csv')\n","    except FileNotFoundError:\n","        netflow_df = None\n","    try:\n","        zeek_df = pd.read_csv('zeek.csv')\n","    except FileNotFoundError:\n","        zeek_df = None\n","    try:\n","        ad_df = pd.read_csv('ad_data.csv')\n","    except FileNotFoundError:\n","        ad_df = None\n","    return netflow_df, zeek_df, ad_df\n","\n","def build_graph_from_data(netflow_df, zeek_df):\n","    \"\"\"Builds a network graph from netflow and zeek data.\"\"\"\n","    print(\"Building graph from data...\")\n","    graph = nx.Graph()\n","    if netflow_df is not None:\n","        for _, row in netflow_df.iterrows():\n","            graph.add_edge(row['source_ip'], row['dest_ip'], type='netflow')\n","    if zeek_df is not None:\n","        for _, row in zeek_df.iterrows():\n","            graph.add_edge(row['id.orig_h'], row['id.resp_h'], type='zeek')\n","    print(f\"Graph built with {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.\")\n","    return graph\n","\n","def analyze_centrality(graph):\n","    \"\"\"Analyzes different centrality measures of the graph.\"\"\"\n","    print(\"Analyzing centrality...\")\n","    if graph.number_of_nodes() == 0:\n","        return {}\n","\n","    centrality_results = {}\n","    centrality_results['degree'] = nx.degree_centrality(graph)\n","    print(\"Degree centrality calculated.\")\n","    centrality_results['betweenness'] = nx.betweenness_centrality(graph)\n","    print(\"Betweenness centrality calculated.\")\n","    centrality_results['closeness'] = nx.closeness_centrality(graph)\n","    print(\"Closeness centrality calculated.\")\n","    try:\n","        centrality_results['eigenvector'] = nx.eigenvector_centrality(graph, max_iter=1000)\n","        print(\"Eigenvector centrality calculated.\")\n","    except nx.PowerIterationFailedConvergence:\n","        centrality_results['eigenvector'] = {n: 0.0 for n in graph.nodes()}\n","        print(\"Eigenvector centrality failed to converge, defaulting to 0.\")\n","\n","    print(\"Centrality analysis complete.\")\n","    return centrality_results\n","\n","def assess_criticality_with_ad(graph, centrality_scores, ad_df):\n","    \"\"\"Assesses asset criticality using a specific centrality score and the Tiered Matrix approach.\"\"\"\n","    if ad_df is None:\n","        print(\"AD data not found. Skipping criticality assessment.\")\n","        return {}\n","\n","    ad_info = ad_df.set_index('ip_address').to_dict('index')\n","\n","    # --- Define Tiers ---\n","    ad_tiers = {}\n","    for ip, data in ad_info.items():\n","        if data.get('is_domain_controller') or data.get('user_privilege') == 'Domain Admin':\n","            ad_tiers[ip] = 'AD Tier 0 (Crown Jewel)'\n","        elif data.get('user_privilege') == 'Privileged User':\n","            ad_tiers[ip] = 'AD Tier 1 (High-Value)'\n","        else:\n","            ad_tiers[ip] = 'AD Tier 2 (Standard)'\n","\n","    network_tiers = {}\n","    if centrality_scores:\n","        score_series = pd.Series(centrality_scores)\n","        # Handle case where all scores are the same, to avoid quantile errors\n","        if score_series.nunique() > 1:\n","            low_quantile = score_series.quantile(0.6)\n","            high_quantile = score_series.quantile(0.8)\n","        else:\n","            low_quantile = high_quantile = score_series.iloc[0]\n","\n","        for ip, score in score_series.items():\n","            if score >= high_quantile:\n","                network_tiers[ip] = 'Network Tier 1 (Critical Hub)'\n","            elif score >= low_quantile:\n","                network_tiers[ip] = 'Network Tier 2 (Connector)'\n","            else:\n","                network_tiers[ip] = 'Network Tier 3 (Endpoint)'\n","\n","    # --- Apply the Criticality Matrix ---\n","    asset_criticality = {}\n","    matrix = {\n","        ('AD Tier 0 (Crown Jewel)', 'Network Tier 1 (Critical Hub)'): 'CRITICAL',\n","        ('AD Tier 0 (Crown Jewel)', 'Network Tier 2 (Connector)'): 'CRITICAL',\n","        ('AD Tier 0 (Crown Jewel)', 'Network Tier 3 (Endpoint)'): 'High',\n","        ('AD Tier 1 (High-Value)', 'Network Tier 1 (Critical Hub)'): 'CRITICAL',\n","        ('AD Tier 1 (High-Value)', 'Network Tier 2 (Connector)'): 'High',\n","        ('AD Tier 1 (High-Value)', 'Network Tier 3 (Endpoint)'): 'Medium',\n","        ('AD Tier 2 (Standard)', 'Network Tier 1 (Critical Hub)'): 'High',\n","        ('AD Tier 2 (Standard)', 'Network Tier 2 (Connector)'): 'Medium',\n","        ('AD Tier 2 (Standard)', 'Network Tier 3 (Endpoint)'): 'Low',\n","    }\n","\n","    for node in graph.nodes():\n","        ad_tier = ad_tiers.get(node, 'AD Tier 2 (Standard)')\n","        net_tier = network_tiers.get(node, 'Network Tier 3 (Endpoint)')\n","        criticality = matrix.get((ad_tier, net_tier), 'Low')\n","        asset_criticality[node] = criticality\n","\n","    return asset_criticality\n","\n","def print_criticality_report(criticality_results, metric_name, top_n=5):\n","    \"\"\"Prints a report of asset criticality for a specific metric.\"\"\"\n","    print(f\"\\n--- Top {top_n} Most Critical Assets (based on {metric_name.upper()}) ---\")\n","    if not criticality_results:\n","        print(\"No criticality results to display.\")\n","        return\n","    order = {'CRITICAL': 0, 'High': 1, 'Medium': 2, 'Low': 3}\n","    sorted_assets = sorted(criticality_results.items(), key=lambda item: order.get(item[1], 99))\n","\n","    top_nodes = []\n","    for asset, level in sorted_assets[:top_n]:\n","        print(f\"Asset: {asset:<15} | Criticality: {level}\")\n","        top_nodes.append(asset)\n","    return top_nodes\n","\n","def visualize_graph(G, centrality_df, asset_criticality, metric_name, top_nodes):\n","    \"\"\"Visualizes the graph, highlighting the top nodes for a specific metric.\"\"\"\n","    print(f\"Creating visualization for {metric_name.upper()}...\")\n","    net = Network(notebook=True, cdn_resources='in_line', height=\"800px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n","\n","    color_map = {'CRITICAL': '#ff4d4d', 'High': '#ffa500', 'Medium': '#ffff00', 'Low': '#4da6ff', 'Unknown': '#cccccc'}\n","\n","    for node in G.nodes():\n","        crit_level = asset_criticality.get(node, 'Unknown')\n","        color = color_map.get(crit_level)\n","        degree = G.degree[node]\n","        size = 10 + (degree * 2)\n","\n","        # Add extra styling for top nodes\n","        border_color = '#FFD700' if node in top_nodes else color\n","        border_width = 3 if node in top_nodes else 1\n","\n","        # Build detailed tooltip\n","        tooltip = f\"<b>IP: {node}</b><br><b>Criticality: {crit_level}</b><hr>\"\n","        if centrality_df is not None and node in centrality_df.index:\n","            tooltip += (f\"Degree: {centrality_df.loc[node, 'degree']:.4f}<br>\"\n","                        f\"Betweenness: {centrality_df.loc[node, 'betweenness']:.4f}<br>\"\n","                        f\"Closeness: {centrality_df.loc[node, 'closeness']:.4f}<br>\"\n","                        f\"Eigenvector: {centrality_df.loc[node, 'eigenvector']:.4f}\")\n","\n","        net.add_node(node, label=node, title=tooltip, color=color, size=size, borderWidth=border_width, borderColor=border_color)\n","\n","    for edge in G.edges():\n","        net.add_edge(edge[0], edge[1], color='#555555')\n","\n","    net.set_options(\"\"\"\n","    const options = {\"physics\": {\"forceAtlas2Based\": {\"gravitationalConstant\": -50, \"centralGravity\": 0.01, \"springLength\": 230, \"springConstant\": 0.08, \"avoidOverlap\": 0.5}, \"minVelocity\": 0.75, \"solver\": \"forceAtlas2Based\"}}\n","    \"\"\")\n","    filename = f\"criticality_graph_{metric_name}.html\"\n","    net.show(filename)\n","    print(f\"Visualization saved to {filename}\")\n","\n","def main():\n","    \"\"\"Main function to run the entire analysis pipeline.\"\"\"\n","    print(\"--- Starting Asset Criticality Analysis Pipeline ---\")\n","    print(\"\\n[STEP 1] Generating synthetic data...\")\n","    generate_and_save_data()\n","\n","    print(\"\\n[STEP 2] Loading data...\")\n","    netflow_df, zeek_df, ad_df = load_data()\n","    if netflow_df is None or zeek_df is None or ad_df is None:\n","        print(\"Halting pipeline due to missing data.\")\n","        return\n","\n","    print(\"\\n[STEP 3] Building graph and analyzing network centrality...\")\n","    graph = build_graph_from_data(netflow_df, zeek_df)\n","    centrality_results = analyze_centrality(graph)\n","    centrality_df = pd.DataFrame(centrality_results).fillna(0)\n","\n","    print(\"\\n[STEP 4] Running comprehensive analysis for each centrality metric...\")\n","    if graph.number_of_nodes() > 0:\n","        for metric_name, scores in centrality_results.items():\n","            # Assess criticality for the current metric\n","            asset_criticality = assess_criticality_with_ad(graph, scores, ad_df)\n","\n","            # Print report and get top nodes for the current metric\n","            top_nodes = print_criticality_report(asset_criticality, metric_name, top_n=5)\n","\n","            # Visualize the results for the current metric\n","            visualize_graph(graph, centrality_df, asset_criticality, metric_name, top_nodes)\n","    else:\n","        print(\"Graph is empty, cannot run analysis or visualize.\")\n","\n","    print(\"\\n--- Pipeline Finished Successfully ---\")\n","\n","if __name__ == '__main__':\n","    main()"],"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/756.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m716.8/756.0 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h--- Starting Asset Criticality Analysis Pipeline ---\n","\n","[STEP 1] Generating synthetic data...\n","Generating synthetic data...\n","Synthetic netflow data saved to netflow.csv\n","Synthetic Zeek data saved to zeek.csv\n","Synthetic Active Directory data saved to ad_data.csv\n","Data generation complete.\n","\n","[STEP 2] Loading data...\n","Loading netflow.csv, zeek.csv, and ad_data.csv...\n","\n","[STEP 3] Building graph and analyzing network centrality...\n","Building graph from data...\n","Graph built with 507 nodes and 1487 edges.\n","Analyzing centrality...\n","Degree centrality calculated.\n","Betweenness centrality calculated.\n","Closeness centrality calculated.\n","Eigenvector centrality calculated.\n","Centrality analysis complete.\n","\n","[STEP 4] Running comprehensive analysis for each centrality metric...\n","\n","--- Top 5 Most Critical Assets (based on DEGREE) ---\n","Asset: 10.0.0.94       | Criticality: CRITICAL\n","Asset: 10.0.0.51       | Criticality: CRITICAL\n","Asset: 10.0.0.206      | Criticality: CRITICAL\n","Asset: 10.0.0.85       | Criticality: CRITICAL\n","Asset: 10.0.0.130      | Criticality: CRITICAL\n","Creating visualization for DEGREE...\n","criticality_graph_degree.html\n","Visualization saved to criticality_graph_degree.html\n","\n","--- Top 5 Most Critical Assets (based on BETWEENNESS) ---\n","Asset: 10.0.0.94       | Criticality: CRITICAL\n","Asset: 10.0.0.206      | Criticality: CRITICAL\n","Asset: 10.0.0.85       | Criticality: CRITICAL\n","Asset: 10.0.0.130      | Criticality: CRITICAL\n","Asset: 10.0.0.229      | Criticality: CRITICAL\n","Creating visualization for BETWEENNESS...\n","criticality_graph_betweenness.html\n","Visualization saved to criticality_graph_betweenness.html\n","\n","--- Top 5 Most Critical Assets (based on CLOSENESS) ---\n","Asset: 10.0.0.94       | Criticality: CRITICAL\n","Asset: 10.0.0.51       | Criticality: CRITICAL\n","Asset: 10.0.0.206      | Criticality: CRITICAL\n","Asset: 10.0.0.85       | Criticality: CRITICAL\n","Asset: 10.0.0.130      | Criticality: CRITICAL\n","Creating visualization for CLOSENESS...\n","criticality_graph_closeness.html\n","Visualization saved to criticality_graph_closeness.html\n","\n","--- Top 5 Most Critical Assets (based on EIGENVECTOR) ---\n","Asset: 10.0.0.94       | Criticality: CRITICAL\n","Asset: 10.0.0.51       | Criticality: CRITICAL\n","Asset: 10.0.0.206      | Criticality: CRITICAL\n","Asset: 10.0.0.85       | Criticality: CRITICAL\n","Asset: 10.0.0.130      | Criticality: CRITICAL\n","Creating visualization for EIGENVECTOR...\n","criticality_graph_eigenvector.html\n","Visualization saved to criticality_graph_eigenvector.html\n","\n","--- Pipeline Finished Successfully ---\n"]}],"execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h74yrPrZG3rl","executionInfo":{"status":"ok","timestamp":1752559782229,"user_tz":-480,"elapsed":14875,"user":{"displayName":"Vasonila Rajesh","userId":"05196519396315335899"}},"outputId":"d18b3eb5-0f20-4aed-a608-b50bb608ae99"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}