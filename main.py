{"cells":[{"cell_type":"code","source":["!pip install pyvis\n","\n","import pandas as pd\n","import numpy as np\n","import networkx as nx\n","from pyvis.network import Network\n","\n","def generate_and_save_data():\n","    \"\"\"Generates synthetic network flow and Zeek data and saves them.\"\"\"\n","    print(\"Generating synthetic data...\")\n","    # Generate synthetic netflow data\n","    num_netflow_entries = 1000\n","    netflow_data = {\n","        'source_ip': [f'192.168.1.{np.random.randint(1, 255)}' for _ in range(num_netflow_entries)],\n","        'dest_ip': [f'10.0.0.{np.random.randint(1, 255)}' for _ in range(num_netflow_entries)],\n","        'source_port': [np.random.randint(1, 65535) for _ in range(num_netflow_entries)],\n","        'dest_port': [np.random.randint(1, 65535) for _ in range(num_netflow_entries)],\n","        'protocol': [np.random.choice(['TCP', 'UDP', 'ICMP']) for _ in range(num_netflow_entries)],\n","        'bytes': [np.random.randint(100, 10000) for _ in range(num_netflow_entries)],\n","        'duration': [np.random.uniform(0.1, 60.0) for _ in range(num_netflow_entries)]\n","    }\n","    netflow_df = pd.DataFrame(netflow_data)\n","    netflow_df.to_csv('netflow.csv', index=False)\n","    print(\"Synthetic netflow data saved to netflow.csv\")\n","\n","    # Generate synthetic Zeek data\n","    num_zeek_entries = 500\n","    zeek_data = {\n","        'timestamp': [pd.to_datetime('2023-01-01') + pd.Timedelta(seconds=i) for i in range(num_zeek_entries)],\n","        'uid': [f'U{i}' for i in range(num_zeek_entries)],\n","        'id.orig_h': [f'192.168.1.{np.random.randint(1, 255)}' for _ in range(num_zeek_entries)],\n","        'id.resp_h': [f'10.0.0.{np.random.randint(1, 255)}' for _ in range(num_zeek_entries)],\n","        'proto': [np.random.choice(['tcp', 'udp', 'icmp']) for _ in range(num_zeek_entries)],\n","        'service': [np.random.choice(['http', 'dns', 'ssh', '-']) for _ in range(num_zeek_entries)],\n","        'duration': [np.random.uniform(0.01, 30.0) for _ in range(num_zeek_entries)]\n","    }\n","    zeek_df = pd.DataFrame(zeek_data)\n","    zeek_df.to_csv('zeek.csv', index=False)\n","    print(\"Synthetic Zeek data saved to zeek.csv\")\n","\n","    print(\"Data generation complete.\")\n","\n","\n","def load_data():\n","    \"\"\"Loads data from CSV files.\"\"\"\n","    print(\"Loading netflow.csv and zeek.csv...\")\n","    try:\n","        netflow_df = pd.read_csv('netflow.csv')\n","        print(\"netflow.csv loaded successfully.\")\n","    except FileNotFoundError:\n","        print(\"Error: netflow.csv not found.\")\n","        netflow_df = None\n","\n","    try:\n","        zeek_df = pd.read_csv('zeek.csv')\n","        print(\"zeek.csv loaded successfully.\")\n","    except FileNotFoundError:\n","        print(\"Error: zeek.csv not found.\")\n","        zeek_df = None\n","\n","    return netflow_df, zeek_df\n","\n","def build_graph_from_data(netflow_df, zeek_df):\n","    \"\"\"Builds a network graph from netflow and zeek data.\"\"\"\n","    print(\"Building graph from data...\")\n","    graph = nx.Graph()\n","\n","    if netflow_df is not None:\n","        for index, row in netflow_df.iterrows():\n","            graph.add_edge(row['source_ip'], row['dest_ip'], type='netflow',\n","                           source_port=row['source_port'], dest_port=row['dest_port'],\n","                           protocol=row['protocol'], bytes=row['bytes'], duration=row['duration'])\n","\n","    if zeek_df is not None:\n","        for index, row in zeek_df.iterrows():\n","            graph.add_edge(row['id.orig_h'], row['id.resp_h'], type='zeek',\n","                           timestamp=row['timestamp'], uid=row['uid'],\n","                           proto=row['proto'], service=row['service'], duration=row['duration'])\n","\n","    print(f\"Graph built with {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.\")\n","    return graph\n","\n","def analyze_centrality(graph):\n","    \"\"\"Analyzes different centrality measures of the graph.\"\"\"\n","    print(\"Analyzing centrality...\")\n","    if graph.number_of_nodes() == 0:\n","        print(\"Graph is empty, cannot analyze centrality.\")\n","        return {}\n","\n","    centrality_results = {}\n","    try:\n","        centrality_results['degree'] = nx.degree_centrality(graph)\n","        print(\"Degree centrality calculated.\")\n","    except Exception as e:\n","        print(f\"Error calculating degree centrality: {e}\")\n","\n","    try:\n","        centrality_results['betweenness'] = nx.betweenness_centrality(graph)\n","        print(\"Betweenness centrality calculated.\")\n","    except Exception as e:\n","        print(f\"Error calculating betweenness centrality: {e}\")\n","\n","    try:\n","        centrality_results['closeness'] = nx.closeness_centrality(graph)\n","        print(\"Closeness centrality calculated.\")\n","    except Exception as e:\n","        print(f\"Error calculating closeness centrality: {e}\")\n","\n","    try:\n","        centrality_results['eigenvector'] = nx.eigenvector_centrality(graph)\n","        print(\"Eigenvector centrality calculated.\")\n","    except Exception as e:\n","        print(f\"Error calculating eigenvector centrality: {e}\")\n","\n","    print(\"Centrality analysis complete.\")\n","    return centrality_results\n","\n","def print_top_assets(centrality_results, top_n=5):\n","    \"\"\"Prints the top assets based on centrality measures.\"\"\"\n","    print(f\"\\nTop {top_n} Assets by Centrality:\")\n","    for metric, results in centrality_results.items():\n","        print(f\"\\n--- {metric.capitalize()} Centrality ---\")\n","        if results:\n","            sorted_assets = sorted(results.items(), key=lambda item: item[1], reverse=True)\n","            for asset, score in sorted_assets[:top_n]:\n","                print(f\"Asset: {asset}, Score: {score:.4f}\")\n","        else:\n","            print(\"No results for this metric.\")\n","\n","def visualize_graph(G, centrality_metric, top_n=10):\n","    # Truncate the graph to only the top N nodes by the given centrality metric\n","    top_nodes = sorted(centrality_metric, key=centrality_metric.get, reverse=True)[:top_n]\n","    subgraph = G.subgraph(top_nodes)\n","\n","    # Create a PyVis network\n","    net = Network(notebook=True, height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n","\n","    # Add nodes and edges from the subgraph\n","    for node in subgraph.nodes():\n","        net.add_node(node, label=node, title=f\"{node}\\\\nDegree: {G.degree[node]}\")\n","    for edge in subgraph.edges():\n","        net.add_edge(edge[0], edge[1])\n","\n","    # Set the physics options\n","    net.set_options(\"\"\"\n","    const options = {\n","      \"physics\": {\n","        \"barnesHut\": {\n","          \"gravitationalConstant\": -80000,\n","          \"centralGravity\": 0.3,\n","          \"springLength\": 250,\n","          \"springConstant\": 0.04,\n","          \"damping\": 0.09,\n","          \"avoidOverlap\": 0.1\n","        },\n","        \"maxVelocity\": 50,\n","        \"minVelocity\": 0.1,\n","        \"solver\": \"barnesHut\",\n","        \"stabilization\": {\n","          \"enabled\": true,\n","          \"iterations\": 1000,\n","          \"updateInterval\": 100,\n","          \"onlyDynamicEdges\": false,\n","          \"fit\": true\n","        },\n","        \"timestep\": 0.5,\n","        \"adaptiveTimestep\": true\n","      }\n","    }\n","    \"\"\")\n","\n","    # Generate the visualization\n","    net.show(\"network_graph.html\")\n","\n","def main():\n","    \"\"\"\n","    Main function to run the entire NCA pipeline.\n","    \"\"\"\n","    print(\"--- Starting Network Centrality Analysis Pipeline ---\")\n","\n","    #Step 1: Generate synthetic data\n","    print(\"\\n[STEP 1/4] Generating synthetic data...\")\n","    generate_and_save_data()\n","    print(\"[STEP 1/4] Data generation complete.\")\n","\n","    # Step 2: Load data and build the graph\n","    print(\"\\n[STEP 2/4] Loading data and building graph...\")\n","    netflow_df, zeek_df = load_data()\n","\n","    if netflow_df is None or zeek_df is None:\n","        print(\"Halting pipeline due to missing data.\")\n","        return\n","\n","    graph = build_graph_from_data(netflow_df, zeek_df)\n","    print(\"[STEP 2/4] Graph construction complete.\")\n","\n","    # Step 3: Analyze centrality and print results\n","    print(\"\\n[STEP 3/4] Analyzing graph centrality...\")\n","    centrality_results = analyze_centrality(graph)\n","    print_top_assets(centrality_results, top_n=5)\n","    print(\"[STEP 3/4] Analysis complete.\")\n","\n","    # Step 4: Visualize the graph\n","    # We will visualize based on degree centrality as it's often the most intuitive.\n","    # You can change 'degree' to 'betweenness', 'closeness', or 'eigenvector'.\n","    print(\"\\n[STEP 4/4] Creating visualization...\")\n","    if graph.number_of_nodes() > 0 and 'degree' in centrality_results:\n","        visualize_graph(graph, centrality_results['degree'], top_n=5) # Adjusted top_n for visualization\n","    else:\n","        print(\"Graph is empty or degree centrality not calculated, cannot visualize.\")\n","    print(\"[STEP 4/4] Visualization complete.\")\n","\n","    print(\"\\n--- Pipeline Finished Successfully ---\")\n","\n","if __name__ == '__main__':\n","    main()"],"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyvis\n","  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis) (7.34.0)\n","Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.11/dist-packages (from pyvis) (3.1.6)\n","Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis) (4.1.1)\n","Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis) (3.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (75.2.0)\n","Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (3.0.51)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (2.19.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.9.6->pyvis) (3.0.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n","Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jedi, pyvis\n","Successfully installed jedi-0.19.2 pyvis-0.3.2\n","--- Starting Network Centrality Analysis Pipeline ---\n","\n","[STEP 1/4] Generating synthetic data...\n","Generating synthetic data...\n","Synthetic netflow data saved to netflow.csv\n","Synthetic Zeek data saved to zeek.csv\n","Data generation complete.\n","[STEP 1/4] Data generation complete.\n","\n","[STEP 2/4] Loading data and building graph...\n","Loading netflow.csv and zeek.csv...\n","netflow.csv loaded successfully.\n","zeek.csv loaded successfully.\n","Building graph from data...\n","Graph built with 506 nodes and 1480 edges.\n","[STEP 2/4] Graph construction complete.\n","\n","[STEP 3/4] Analyzing graph centrality...\n","Analyzing centrality...\n","Degree centrality calculated.\n","Betweenness centrality calculated.\n","Closeness centrality calculated.\n","Eigenvector centrality calculated.\n","Centrality analysis complete.\n","\n","Top 5 Assets by Centrality:\n","\n","--- Degree Centrality ---\n","Asset: 10.0.0.147, Score: 0.0277\n","Asset: 192.168.1.206, Score: 0.0257\n","Asset: 10.0.0.139, Score: 0.0257\n","Asset: 10.0.0.122, Score: 0.0257\n","Asset: 10.0.0.86, Score: 0.0238\n","\n","--- Betweenness Centrality ---\n","Asset: 10.0.0.147, Score: 0.0262\n","Asset: 192.168.1.206, Score: 0.0252\n","Asset: 10.0.0.82, Score: 0.0235\n","Asset: 192.168.1.105, Score: 0.0233\n","Asset: 10.0.0.139, Score: 0.0228\n","\n","--- Closeness Centrality ---\n","Asset: 10.0.0.139, Score: 0.2988\n","Asset: 10.0.0.147, Score: 0.2985\n","Asset: 192.168.1.42, Score: 0.2978\n","Asset: 192.168.1.105, Score: 0.2978\n","Asset: 192.168.1.7, Score: 0.2964\n","\n","--- Eigenvector Centrality ---\n","Asset: 10.0.0.147, Score: 0.1154\n","Asset: 192.168.1.42, Score: 0.1005\n","Asset: 10.0.0.139, Score: 0.0971\n","Asset: 192.168.1.30, Score: 0.0960\n","Asset: 10.0.0.185, Score: 0.0958\n","[STEP 3/4] Analysis complete.\n","\n","[STEP 4/4] Creating visualization...\n","Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n","network_graph.html\n","[STEP 4/4] Visualization complete.\n","\n","--- Pipeline Finished Successfully ---\n"]}],"execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"35S8u-hg4CVD","executionInfo":{"status":"ok","timestamp":1750661935273,"user_tz":-480,"elapsed":26826,"user":{"displayName":"Vasonila Rajesh","userId":"05196519396315335899"}},"outputId":"2d52b9b1-2cfc-47b8-cc47-fb51d779b9e2"}},{"cell_type":"code","metadata":{"id":"0af8e8f2"},"source":["import pandas as pd\n","import numpy as np\n","\n","def generate_and_save_data():\n","    \"\"\"Generates synthetic network flow and Zeek data and saves them.\"\"\"\n","    print(\"Generating synthetic data...\")\n","    # Generate synthetic netflow data\n","    num_netflow_entries = 1000\n","    netflow_data = {\n","        'source_ip': [f'192.168.1.{np.random.randint(1, 255)}' for _ in range(num_netflow_entries)],\n","        'dest_ip': [f'10.0.0.{np.random.randint(1, 255)}' for _ in range(num_netflow_entries)],\n","        'source_port': [np.random.randint(1, 65535) for _ in range(num_netflow_entries)],\n","        'dest_port': [np.random.randint(1, 65535) for _ in range(num_netflow_entries)],\n","        'protocol': [np.random.choice(['TCP', 'UDP', 'ICMP']) for _ in range(num_netflow_entries)],\n","        'bytes': [np.random.randint(100, 10000) for _ in range(num_netflow_entries)],\n","        'duration': [np.random.uniform(0.1, 60.0) for _ in range(num_netflow_entries)]\n","    }\n","    netflow_df = pd.DataFrame(netflow_data)\n","    netflow_df.to_csv('netflow.csv', index=False)\n","    print(\"Synthetic netflow data saved to netflow.csv\")\n","\n","    # Generate synthetic Zeek data\n","    num_zeek_entries = 500\n","    zeek_data = {\n","        'timestamp': [pd.to_datetime('2023-01-01') + pd.Timedelta(seconds=i) for i in range(num_zeek_entries)],\n","        'uid': [f'U{i}' for i in range(num_zeek_entries)],\n","        'id.orig_h': [f'192.168.1.{np.random.randint(1, 255)}' for _ in range(num_zeek_entries)],\n","        'id.resp_h': [f'10.0.0.{np.random.randint(1, 255)}' for _ in range(num_zeek_entries)],\n","        'proto': [np.random.choice(['tcp', 'udp', 'icmp']) for _ in range(num_zeek_entries)],\n","        'service': [np.random.choice(['http', 'dns', 'ssh', '-']) for _ in range(num_zeek_entries)],\n","        'duration': [np.random.uniform(0.01, 30.0) for _ in range(num_zeek_entries)]\n","    }\n","    zeek_df = pd.DataFrame(zeek_data)\n","    zeek_df.to_csv('zeek.csv', index=False)\n","    print(\"Synthetic Zeek data saved to zeek.csv\")\n","\n","    print(\"Data generation complete.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dcaf0a13"},"source":["import pandas as pd\n","import networkx as nx\n","\n","def load_data():\n","    \"\"\"Loads data from CSV files.\"\"\"\n","    print(\"Loading netflow.csv and zeek.csv...\")\n","    try:\n","        netflow_df = pd.read_csv('netflow.csv')\n","        print(\"netflow.csv loaded successfully.\")\n","    except FileNotFoundError:\n","        print(\"Error: netflow.csv not found.\")\n","        netflow_df = None\n","\n","    try:\n","        zeek_df = pd.read_csv('zeek.csv')\n","        print(\"zeek.csv loaded successfully.\")\n","    except FileNotFoundError:\n","        print(\"Error: zeek.csv not found.\")\n","        zeek_df = None\n","\n","    return netflow_df, zeek_df\n","\n","def build_graph_from_data(netflow_df, zeek_df):\n","    \"\"\"Builds a network graph from netflow and zeek data.\"\"\"\n","    print(\"Building graph from data...\")\n","    graph = nx.Graph()\n","\n","    if netflow_df is not None:\n","        for index, row in netflow_df.iterrows():\n","            graph.add_edge(row['source_ip'], row['dest_ip'], type='netflow',\n","                           source_port=row['source_port'], dest_port=row['dest_port'],\n","                           protocol=row['protocol'], bytes=row['bytes'], duration=row['duration'])\n","\n","    if zeek_df is not None:\n","        for index, row in zeek_df.iterrows():\n","            graph.add_edge(row['id.orig_h'], row['id.resp_h'], type='zeek',\n","                           timestamp=row['timestamp'], uid=row['uid'],\n","                           proto=row['proto'], service=row['service'], duration=row['duration'])\n","\n","    print(f\"Graph built with {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.\")\n","    return graph\n","\n","def analyze_centrality(graph):\n","    \"\"\"Analyzes different centrality measures of the graph.\"\"\"\n","    print(\"Analyzing centrality...\")\n","    if graph.number_of_nodes() == 0:\n","        print(\"Graph is empty, cannot analyze centrality.\")\n","        return {}\n","\n","    centrality_results = {}\n","    try:\n","        centrality_results['degree'] = nx.degree_centrality(graph)\n","        print(\"Degree centrality calculated.\")\n","    except Exception as e:\n","        print(f\"Error calculating degree centrality: {e}\")\n","\n","    try:\n","        centrality_results['betweenness'] = nx.betweenness_centrality(graph)\n","        print(\"Betweenness centrality calculated.\")\n","    except Exception as e:\n","        print(f\"Error calculating betweenness centrality: {e}\")\n","\n","    try:\n","        centrality_results['closeness'] = nx.closeness_centrality(graph)\n","        print(\"Closeness centrality calculated.\")\n","    except Exception as e:\n","        print(f\"Error calculating closeness centrality: {e}\")\n","\n","    try:\n","        centrality_results['eigenvector'] = nx.eigenvector_centrality(graph)\n","        print(\"Eigenvector centrality calculated.\")\n","    except Exception as e:\n","        print(f\"Error calculating eigenvector centrality: {e}\")\n","\n","    print(\"Centrality analysis complete.\")\n","    return centrality_results\n","\n","def print_top_assets(centrality_results, top_n=5):\n","    \"\"\"Prints the top assets based on centrality measures.\"\"\"\n","    print(f\"\\nTop {top_n} Assets by Centrality:\")\n","    for metric, results in centrality_results.items():\n","        print(f\"\\n--- {metric.capitalize()} Centrality ---\")\n","        if results:\n","            sorted_assets = sorted(results.items(), key=lambda item: item[1], reverse=True)\n","            for asset, score in sorted_assets[:top_n]:\n","                print(f\"Asset: {asset}, Score: {score:.4f}\")\n","        else:\n","            print(\"No results for this metric.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f519b55f"},"source":["import networkx as nx\n","from pyvis.network import Network\n","\n","def visualize_graph(G, centrality_metric, top_n=10):\n","    # Truncate the graph to only the top N nodes by the given centrality metric\n","    top_nodes = sorted(centrality_metric, key=centrality_metric.get, reverse=True)[:top_n]\n","    subgraph = G.subgraph(top_nodes)\n","\n","    # Create a PyVis network\n","    net = Network(notebook=True, height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n","\n","    # Add nodes and edges from the subgraph\n","    for node in subgraph.nodes():\n","        net.add_node(node, label=node, title=f\"{node}\\\\nDegree: {G.degree[node]}\")\n","    for edge in subgraph.edges():\n","        net.add_edge(edge[0], edge[1])\n","\n","    # Add the options to enable the physics configuration UI\n","    net.show_buttons(filter_=['physics'])\n","\n","    # Generate the visualization\n","    net.show(\"network_graph.html\")"],"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}